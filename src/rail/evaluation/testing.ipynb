{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables_io\n",
    "import qp\n",
    "import numpy as np\n",
    "\n",
    "from rail.evaluation.dist_to_dist_evaluator import DistToDistEvaluator\n",
    "from rail.evaluation.dist_to_point_evaluator import DistToPointEvaluator\n",
    "from rail.evaluation.point_to_point_evaluator import PointToPointEvaluator\n",
    "from rail.evaluation.single_evaluator import SingleEvaluator\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.data import QPHandle, TableHandle, QPOrTableHandle\n",
    "\n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rail.core.utils import find_rail_file\n",
    "possible_local_file = './examples_data/evaluation_data/data/output_fzboost.hdf5'\n",
    "if os.path.exists(possible_local_file):\n",
    "    pdfs_file = os.path.abspath(possible_local_file)\n",
    "else:\n",
    "    pdfs_file = 'examples_data/evaluation_data/data/output_fzboost.hdf5'\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(pdfs_file))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    curl_com = f\"curl -o {pdfs_file} https://portal.nersc.gov/cfs/lsst/PZ/output_fzboost.hdf5\"\n",
    "    os.system(curl_com)\n",
    "\n",
    "ztrue_file = find_rail_file('examples_data/testdata/test_dc2_validation_9816.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = DS.read_file(key='pdfs_data', handle_class=QPHandle, path=pdfs_file)\n",
    "ztrue_data = DS.read_file('ztrue_data', TableHandle, ztrue_file)\n",
    "#truth = DS.add_data('truth', ztrue_data()['photometry'], TableHandle, path=ztrue_file)\n",
    "#truth_points = DS.add_data('truth_points', ztrue_data()['photometry']['redshift'], TableHandle, path=ztrue_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dist to Dist Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'cvm' takes about 3.5 minutes to run\n",
    "# 'ad' takes about ~4 minutes to run\n",
    "# 'ks' takes about 2.75 minutes to run\n",
    "# 'kld' takes about X minutes to run\n",
    "\n",
    "stage_dict = dict(\n",
    "    metrics=['cvm', 'ks', 'rmse', 'kld', 'ad'],\n",
    "    _random_state=None,\n",
    ")\n",
    "\n",
    "dtd_stage = DistToDistEvaluator.make_stage(name='dist_to_dist', **stage_dict)\n",
    "dtd_stage_single = DistToDistEvaluator.make_stage(name='dist_to_dist', force_exact=True, **stage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelized implementation\n",
    "dtd_results = dtd_stage.evaluate(ensemble, ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-parallelized, exact implementation\n",
    "dtd_results_single = dtd_stage_single.evaluate(ensemble, ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = tables_io.convertObj(dtd_results(), tables_io.types.PD_DATAFRAME)\n",
    "results_df_single = tables_io.convertObj(dtd_results_single(), tables_io.types.PD_DATAFRAME)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dist to Point Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_dict = dict(\n",
    "    metrics=['cdeloss', 'pit', 'brier'],\n",
    "    _random_state=None,\n",
    "    metric_config={\n",
    "        'brier': {'limits':(0,3.1)},\n",
    "        'pit':{'tdigest_compression': 1000},\n",
    "    }\n",
    ")\n",
    "dtp_stage = DistToPointEvaluator.make_stage(name='dist_to_point', **stage_dict)\n",
    "dtp_stage_single = DistToPointEvaluator.make_stage(name='dist_to_point', force_exact=True, **stage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtp_results = dtp_stage.evaluate(ensemble, ztrue_data)\n",
    "results_df = tables_io.convertObj(dtp_results['summary'](), tables_io.types.PD_DATAFRAME)\n",
    "\n",
    "dtp_pit = dtp_stage.get_handle('single_distribution_summary').read()['pit']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtp_results_single = dtp_stage_single.evaluate(ensemble, ztrue_data)\n",
    "results_df_single = tables_io.convertObj(dtp_results_single['summary'](), tables_io.types.PD_DATAFRAME)\n",
    "\n",
    "dtp_pit_single = dtp_stage_single.get_handle('single_distribution_summary').read()['pit']\n",
    "results_df_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xgrid = np.linspace(0.05,0.95,100)\n",
    "a_pdf = dtp_pit.pdf(xgrid)\n",
    "b_pdf = dtp_pit_single.pdf(xgrid)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xgrid, np.squeeze(a_pdf), label='parallelized, tdigest approximation')\n",
    "plt.plot(xgrid, np.squeeze(b_pdf), label='non-parallelized, exact')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point to Point Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_dict = dict(\n",
    "    metrics=['point_stats_ez', 'point_stats_iqr', 'point_bias', 'point_outlier_rate', 'point_stats_sigma_mad'],\n",
    "    _random_state=None,\n",
    "    hdf5_groupname='photometry',\n",
    "    point_estimate_key='zmode',\n",
    "    chunk_size=10000,\n",
    "    metric_config={\n",
    "        'point_stats_iqr':{'tdigest_compression': 100},\n",
    "    }\n",
    ")\n",
    "ptp_stage = PointToPointEvaluator.make_stage(name='point_to_point', **stage_dict)\n",
    "ptp_stage_single = PointToPointEvaluator.make_stage(name='point_to_point', force_exact=True, **stage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptp_results = ptp_stage.evaluate(ensemble, ztrue_data)\n",
    "results_summary = tables_io.convertObj(ptp_stage.get_handle('summary')(), tables_io.types.PD_DATAFRAME)\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptp_results_single = ptp_stage_single.evaluate(ensemble, ztrue_data)\n",
    "results_summary_single = tables_io.convertObj(ptp_stage_single.get_handle('summary')(), tables_io.types.PD_DATAFRAME)\n",
    "results_summary_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = ztrue_data()['photometry']['redshift']\n",
    "estimates = np.squeeze(ensemble().ancil['zmode'])\n",
    "#truth_points = DS.add_data('truth_points', ztrue_data()['photometry']['redshift'], TableHandle, path=ztrue_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_iqr = qp.metrics.point_estimate_metric_classes.PointSigmaIQR().evaluate(estimates, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = (estimates- truth)/(1.+truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'pdfs_data':'examples_data/evaluation_data/data/output_fzboost.hdf5',\n",
    "    'ztrue_data':'examples_data/test_dc2_validation_9816.hdf5',\n",
    "}\n",
    "outputs = {\n",
    "    'output':'output.hdf5',\n",
    "    'summary':'summary.hdf5',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.core import RailPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = RailPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.add_stage(ptp_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.initialize(overall_inputs=inputs, run_config={'output_dir':'.', 'log_dir':'.', 'resume':False}, stages_config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.save('eval_pipe.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_dict = dict(\n",
    "    metrics=['cvm', 'ks', 'omega', 'kld', 'cdeloss', 'point_stats_ez', 'point_stats_iqr'],\n",
    "    _random_state=None,\n",
    "    hdf5_groupname='photometry',\n",
    "    point_estimates=['zmode'],\n",
    "    truth_point_estimates=['redshift'],\n",
    "    chunk_size=1000,\n",
    ")\n",
    "ensemble_d = DS.add_data('pdfs_data_2', None, QPOrTableHandle, path=pdfs_file)\n",
    "ztrue_data_d = DS.add_data('ztrue_data_2', None, QPOrTableHandle, path=ztrue_file)\n",
    "\n",
    "single_stage = SingleEvaluator.make_stage(name='single', **stage_dict)\n",
    "single_stage_single = SingleEvaluator.make_stage(name='single', force_exact=True, **stage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_results = single_stage.evaluate(ensemble_d, ztrue_data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_results_single = single_stage_single.evaluate(ensemble_d, ztrue_data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_stage.get_handle('output')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_stage.get_handle('summary')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_stage_single.get_handle('output')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_stage_single.get_handle('summary')()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
